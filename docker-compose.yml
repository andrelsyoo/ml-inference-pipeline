version: '3.8'

services:
  tf-serving:
    image: tensorflow/serving:latest
    container_name: tf-serving
    ports:
      - "8501:8501"  # REST API
      - "8500:8500"  # gRPC API (optional)
    volumes:
      - ./models/mobilenet:/models/mobilenet
    environment:
      - MODEL_NAME=mobilenet
    command:
      - "--rest_api_port=8501"
      - "--model_name=mobilenet"
      - "--model_base_path=/models/mobilenet"
    healthcheck:
      test: ["CMD-SHELL", "timeout 5 bash -c '</dev/tcp/localhost/8501' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - ml-network

  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    container_name: ml-gateway
    ports:
      - "8000:8000"
    depends_on:
      tf-serving:
        condition: service_healthy
    environment:
      - TF_SERVING_URL=http://tf-serving:8501/v1/models/mobilenet:predict
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health', timeout=5)"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - ml-network

networks:
  ml-network:
    driver: bridge